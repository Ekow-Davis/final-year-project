{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45425193-ce1a-45ba-9522-791683ef5780",
   "metadata": {},
   "source": [
    "MRI Dataset Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010ff7ef-d09c-4433-b781-96e24c9b9124",
   "metadata": {},
   "source": [
    "We will perform teh following steps to the data\n",
    "Merge\n",
    "Resize\n",
    "Split and Save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8375fc1d-0b29-4cc4-b476-7b53c9ef7827",
   "metadata": {},
   "source": [
    "Merging both datasets of Training and Test from the orignial data and randomly splitting after resizeing to ensure the data is randomised and properly representing the system without deviating from the orginal implementation methods of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f1c13f-6fcd-4d67-8b66-03186dc78251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy<2.3.0,>=2 (from opencv-python)\n",
      "  Downloading numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "   ---------------------------------------- 0.0/39.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.4/39.0 MB 11.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 4.7/39.0 MB 11.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 6.8/39.0 MB 11.3 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 9.4/39.0 MB 11.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 11.5/39.0 MB 11.8 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.4/39.0 MB 11.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 16.8/39.0 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 19.4/39.0 MB 11.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 22.3/39.0 MB 12.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.6/39.0 MB 12.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 27.3/39.0 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 29.9/39.0 MB 12.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.5/39.0 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.1/39.0 MB 12.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.7/39.0 MB 12.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/39.0 MB 12.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.0/39.0 MB 11.3 MB/s eta 0:00:00\n",
      "Downloading numpy-2.2.6-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.6/12.6 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 12.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.9/12.6 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 10.5 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, opencv-python\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-2.2.6 opencv-python-4.12.0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ekowd\\anaconda3\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.2.6 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a383db-1516-47fd-a698-196b5954573d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version: 4.12.0\n",
      "NumPy version: 2.2.6\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "print(\"NumPy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff5bf38c-2db0-47a8-87c5-ba7491f1e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba656e87-f677-4e33-9a62-dfd6ae151777",
   "metadata": {},
   "source": [
    "Since the raw data is already stored in the project repository, we'll call it from there rather than kaggle directly.\n",
    "\n",
    "We will define the specific path for the raw data folders and the file path for the folder we will store the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8622961f-c6cd-4386-837e-a269091cc6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Paths\n",
    "RAW_TRAIN_DIR = Path(r\"..\\\\data\\\\raw_data\\\\Training\")\n",
    "RAW_TEST_DIR  = Path(r\"..\\\\data\\\\raw_data\\\\Testing\")\n",
    "CLEAN_DIR     = Path(r\"..\\\\data\\\\cleaned_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ff8ee-a0aa-4568-af60-83b62dfb9d51",
   "metadata": {},
   "source": [
    "Next we will create the folder structure in the clean directory since we plan to split the data into train, test and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ebece1e-9293-40e7-84bf-9d093ea7d3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder structure created under: ..\\data\\cleaned_data\n"
     ]
    }
   ],
   "source": [
    "# Configuration \n",
    "CLASSES = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "IMG_SIZE = (224, 224)\n",
    "SPLIT_RATIOS = {'train': 0.8, 'val': 0.1, 'test': 0.1}\n",
    "\n",
    "# Create Folder Structure \n",
    "for split in ['train', 'val', 'test']:\n",
    "    for cls in CLASSES:\n",
    "        path = CLEAN_DIR / split / cls\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Folder structure created under:\", CLEAN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c200f5c5-fef6-44d3-b9d5-3332541f7272",
   "metadata": {},
   "source": [
    "Next we prepare the function to Load, Resize and collect the images, resizing them to 224x224 which provide the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8abd7ba1-f735-4861-bc5e-e21f3433e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Load, Resize, and Collect Image Paths\n",
    "def load_and_resize_images(class_name):\n",
    "    \"\"\"\n",
    "    Combines training and testing images for a given class,\n",
    "    resizes to 224x224, and returns a list of (image_array, filename).\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    # Combine both train and test directories\n",
    "    for data_dir in [RAW_TRAIN_DIR, RAW_TEST_DIR]:\n",
    "        class_dir = data_dir / class_name\n",
    "        if not class_dir.exists():\n",
    "            print(f\" Skipped missing directory: {class_dir}\")\n",
    "            continue\n",
    "        for img_file in class_dir.glob('*'):\n",
    "            try:\n",
    "                img = cv2.imread(str(img_file))\n",
    "                if img is None:\n",
    "                    continue\n",
    "                img_resized = cv2.resize(img, IMG_SIZE)\n",
    "                images.append((img_resized, img_file.name))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_file}: {e}\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203014da-ae32-4b07-ac95-b5f1e8f2df02",
   "metadata": {},
   "source": [
    "Then we store the now resized images, passing it to our saving function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0b30100-3525-4e02-a0bf-5c78f3dd6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Save Images \n",
    "def save_images(images, save_dir, class_name):\n",
    "    \"\"\"\n",
    "    Saves a list of (image_array, filename) into a given directory.\n",
    "    \"\"\"\n",
    "    for img_array, filename in images:\n",
    "        save_path = save_dir / class_name / filename\n",
    "        cv2.imwrite(str(save_path), img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6632b590-b8cf-4e36-96a9-63364f9edc20",
   "metadata": {},
   "source": [
    "Now we process the classes for each type of tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e871ca-4ae3-4230-b7d2-a511cb9ead79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing class: glioma\n",
      "Total images found (merged): 1621\n",
      "   Saving training images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saving validation images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saving testing images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done: glioma | Train: 1296 | Val: 162 | Test: 163\n",
      "\n",
      " Processing class: meningioma\n",
      "Total images found (merged): 1645\n",
      "   Saving training images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saving validation images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saving testing images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done: meningioma | Train: 1316 | Val: 164 | Test: 165\n",
      "\n",
      " Processing class: notumor\n",
      "Total images found (merged): 2000\n",
      "   Saving training images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saving validation images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saving testing images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done: notumor | Train: 1600 | Val: 200 | Test: 200\n",
      "\n",
      " Processing class: pituitary\n",
      "Total images found (merged): 1757\n",
      "   Saving training images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saving validation images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saving testing images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done: pituitary | Train: 1405 | Val: 176 | Test: 176\n",
      "\n",
      " Dataset successfully cleaned, resized, and split!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Process Each Class (Create missing raw dirs, handle 0/1 images, deterministic split)\n",
    "for cls in CLASSES:\n",
    "    print(f\"\\n Processing class: {cls}\")\n",
    "    images = load_and_resize_images(cls)\n",
    "    total_images = len(images)\n",
    "    print(f\"Total images found (merged): {total_images}\")\n",
    "\n",
    "    # Skip if no images found\n",
    "    if total_images == 0:\n",
    "        print(f\" Skipping '{cls}' â€” no images found in Training or Testing directories.\")\n",
    "        continue\n",
    "\n",
    "    # Skip splitting if too few images for 3 sets\n",
    "    if total_images < 3:\n",
    "        print(f\" Too few images ({total_images}) for splitting. Saving all to 'train' folder.\")\n",
    "        save_images(tqdm(images, leave=False), CLEAN_DIR / 'train', cls)\n",
    "        continue\n",
    "\n",
    "    # Prepare numpy arrays for splitting\n",
    "    X = np.arange(total_images)\n",
    "    y = [cls] * total_images\n",
    "\n",
    "    # Split: train (80%) + temp (20%)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=(1 - SPLIT_RATIOS['train']), random_state=42, shuffle=True\n",
    "    )\n",
    "    # Split temp into val (10%) and test (10%)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Map indices to image data\n",
    "    train_imgs = [images[i] for i in X_train]\n",
    "    val_imgs   = [images[i] for i in X_val]\n",
    "    test_imgs  = [images[i] for i in X_test]\n",
    "\n",
    "    # Save into respective folders\n",
    "    print(\"   Saving training images...\")\n",
    "    save_images(tqdm(train_imgs, leave=False), CLEAN_DIR / 'train', cls)\n",
    "\n",
    "    print(\"   Saving validation images...\")\n",
    "    save_images(tqdm(val_imgs, leave=False), CLEAN_DIR / 'val', cls)\n",
    "\n",
    "    print(\"   Saving testing images...\")\n",
    "    save_images(tqdm(test_imgs, leave=False), CLEAN_DIR / 'test', cls)\n",
    "\n",
    "    print(f\" Done: {cls} | Train: {len(train_imgs)} | Val: {len(val_imgs)} | Test: {len(test_imgs)}\")\n",
    "\n",
    "print(\"\\n Dataset successfully cleaned, resized, and split!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec05d2-5fae-413e-b195-c4af5eeb6b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef27ef7-f77e-4d52-9d66-d90b2447639c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
